# DATABASE_URL=postgresql://postgres:postgres@localhost:5432/literature_db
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/literature_db


REDIS_URL=redis://redis:6379/0
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/1

# ===== LLM Configuration =====
# Centralized LLM service configuration (app/llm/service.py)
# All LLM calls throughout the system use these settings

# LLM provider: "dummy" (default, safe), "openai", "nvidia", or future local models
LLM_PROVIDER=nvidia

# LLM model name (provider-specific)
# OpenAI: gpt-4o-mini, gpt-3.5-turbo, gpt-4, etc.
# NVIDIA: nvidia/llama3-chatqa-1.5-8b, etc.
LLM_MODEL=nvidia/llama3-chatqa-1.5-8b

# LLM temperature (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.0

# LLM max tokens per response
LLM_MAX_TOKENS=800

# OpenAI API key (if using LLM_PROVIDER=openai)
# OPENAI_API_KEY=sk-your-key-here

# NVIDIA credentials (if using LLM_PROVIDER=nvidia)
NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1
NVIDIA_API_KEY=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

# ===== Phase-1: Ingestion Configuration =====
MINIMUM_EDGE_SUPPORT=2

# Text Classifier mode: "deterministic" (fast, no LLM) or "llm" (semantic understanding)
TEXT_CLASSIFIER_MODE=deterministic

# Enable lexical repair to fix layout-induced word splits (e.g., "para-\ngraph" â†’ "paragraph")
# 0 = disabled (default behavior), 1 = enabled (applies repair during normalization)
ENABLE_LEXICAL_REPAIR=0

# Ingestion segmentation strategy: "sentences" or other strategies
INGESTION_SEGMENTATION_STRATEGY=sentences

# Number of sentences per text block
INGESTION_SENTENCES_PER_BLOCK=3

# ===== Phase-5: Decision & Control Configuration =====

# Decision provider strategy: "rule_based" (default), "hybrid", or "llm"
DECISION_PROVIDER=rule_based

# Enable LLM-based clarification question generation (if using AskUserInputHandler)
# 0 = use template-based questions, 1 = use LLM service
CLARIFICATION_USE_LLM=0

# Confidence normalization: divide raw support count by this to get [0,1] range
# Raw confidence from Phase-4 is integer support count; normalized_conf = min(raw / factor, 1.0)
DECISION_CONFIDENCE_NORM_FACTOR=5

# High confidence threshold for HALT_CONFIDENT decision
# If max_normalized_confidence >= this AND dominant hypothesis is clear, return HALT_CONFIDENT
DECISION_HIGH_CONFIDENCE_THRESHOLD=0.7

# Low confidence threshold for RETRY_WITH_RELAXED_FILTERS decision
# If mean_normalized_confidence < this, return RETRY_WITH_RELAXED_FILTERS
DECISION_LOW_CONFIDENCE_THRESHOLD=0.5

# Dominant hypothesis gap ratio
# Hypothesis is "clearly dominant" if (1st_conf - 2nd_conf) > gap_ratio * max_conf
# Example: 1st=0.8, 2nd=0.6, gap=0.2; 0.2 > 0.3*0.8=0.24? No, so NOT dominant if gap_ratio=0.3
DECISION_DOMINANT_GAP_RATIO=0.3

# Low diversity threshold: unique source-target pairs
# If unique_source_target_pairs < this, diversity is considered low, return ASK_DOMAIN_EXPERT
DECISION_LOW_DIVERSITY_PAIRS_THRESHOLD=2

# Low diversity threshold: diversity score ratio
# If diversity_score (unique_nodes / total_nodes) < this, diversity is low, return ASK_DOMAIN_EXPERT
DECISION_DIVERSITY_RATIO_THRESHOLD=0.3

# Sparse graph density threshold
# If graph_density (edges / max_possible_edges) < this, graph is sparse, return FETCH_MORE_LITERATURE
DECISION_SPARSE_GRAPH_DENSITY_THRESHOLD=0.05

# Filtered-to-total ratio threshold (diagnostic warning)
# If passed_hypotheses / total_hypotheses < this, indicates low filter pass rate (not a decision driver)
DECISION_PASSED_TO_TOTAL_RATIO_THRESHOLD=0.2

# Minimum viable hypotheses threshold
# If total_hypothesis_count < this, return INSUFFICIENT_SIGNAL
DECISION_MINIMUM_HYPOTHESES_THRESHOLD=1

# ===== Indirect Path Measurements Configuration =====
# Enable/disable indirect path-based measurements (compute or skip)
INDIRECT_PATH_MEASUREMENTS_ENABLED=true

# Enable temporal placeholder measurements (evidence_growth_rate, hypothesis_stability, time_since_last_update)
# These read previous snapshots but do NOT influence decisions yet
INDIRECT_PATH_TEMPORAL_PLACEHOLDERS=true

# Dominance clarity threshold: confidence gap above this = clear dominant
INDIRECT_PATH_DOMINANCE_GAP_THRESHOLD=0.2

# Path length thresholds for structural analysis
INDIRECT_PATH_MIN_LENGTH=3
INDIRECT_PATH_MAX_LENGTH=4

# ===== Phase-3: Semantic Graph Configuration =====
# Similarity threshold for semantic merging (cosine similarity, 0.0-1.0)
# 0.85 = safe (standard industry default), 0.90 = strict (fewer clusters), 0.80 = lenient (more clusters)
SEMANTIC_SIMILARITY_THRESHOLD=0.85

# ===== Phase-4: Path Reasoning Configuration =====
# Maximum number of hops for path reasoning algorithm
PATH_REASONING_MAX_HOPS=2

# Allow 3-hop paths in query mode (if enabled)
PATH_REASONING_ALLOW_LEN3=false
# ===== FETCH_MORE Literature Pipeline Configuration =====

# --- Fingerprinting Configuration ---
# Algorithm for content-based paper fingerprinting: 'md5' or 'sha256' (default)
FINGERPRINT_ALGORITHM=sha256

# Similarity threshold (0.0-1.0) for considering fingerprints equivalent
# Higher = stricter matching, lower = more tolerant of variations
FINGERPRINT_SIMILARITY_THRESHOLD=0.95

# Components to include in fingerprint hash (comma-separated)
# Options: 'title', 'abstract', 'authors'
FINGERPRINT_COMPONENTS=title,abstract

# --- Domain Resolution Configuration ---
# Deterministic confidence threshold for domain detection
# If deterministic signal < threshold, fall back to LLM for closed-set classification
DOMAIN_DETERMINISTIC_THRESHOLD=0.7

# LLM confidence threshold for accepting LLM domain classification result
# If LLM confidence < threshold, domain remains None
DOMAIN_LLM_THRESHOLD=0.6

# LLM prompt file path for domain resolution (relative to prompts directory)
DOMAIN_RESOLVER_PROMPT_FILE=domain_resolver.txt

# Available domain labels for closed-set classification (comma-separated)
# Used by domain resolver LLM fallback
DOMAIN_LABELS=biomedical,computer_science,physics,chemistry,mathematics,engineering

# Domain-to-keyword mappings for deterministic resolution (JSON)
# Format: {"domain_name": ["keyword1", "keyword2", ...], ...}
# Keywords are matched case-insensitively and as substrings against hypothesis labels
DOMAIN_KEYWORDS={"biomedical": ["disease", "patient", "clinical", "medical", "drug", "treatment", "therapy", "protein", "gene"], "computer_science": ["algorithm", "network", "database", "software", "system", "machine", "learning", "neural", "model"], "physics": ["particle", "wave", "quantum", "field", "force", "energy", "relativity", "mechanics"], "chemistry": ["molecule", "reaction", "bond", "compound", "element", "atomic", "electron"], "mathematics": ["theorem", "proof", "equation", "function", "integral", "derivative", "convergence"], "engineering": ["design", "structure", "bridge", "circuit", "system", "control", "optimization"]}

# --- Paper Provider Configuration ---
# Enabled providers for fetching (comma-separated)
# Options: 'arxiv', 'crossref', 'pubmed'
FETCH_PROVIDERS=semantic_scholar

# Maximum papers per batch
FETCH_BATCH_SIZE=1

# Maximum paper fetch per
FETCH_RESULTS_LIMIT=25

# Provider API timeout in seconds
FETCH_TIMEOUT_SECONDS=30

# Number of retry attempts for failed provider calls
FETCH_RETRY_ATTEMPTS=3

# --- SearchQuery Configuration ---
# Length of hypothesis_signature hash (characters, max 64)
QUERY_SIGNATURE_LENGTH=64

# Initial reputation score for new SearchQueries
QUERY_INITIAL_REPUTATION=0

# Reputation adjustment on query exhaustion (negative typically)
QUERY_REPUTATION_EXHAUSTION_DECAY=-5

# Maximum reuse attempts before marking query exhausted
QUERY_MAX_REUSE_ATTEMPTS=3

# --- FetchService Configuration ---
# Number of top-ranked hypotheses to fetch for in one FETCH_MORE cycle
# Hypotheses ranked by reputation and status (new > reusable)
FETCH_TOP_K_HYPOTHESES=1

# Minimum reputation threshold to consider hypothesis for fetching
# Queries below this score are skipped even if in top-K
FETCH_MIN_REPUTATION=-10

# --- Signal Computation Configuration ---
# Thresholds for classifying signal as positive, zero, or negative
# Positive: delta >= this threshold (strengthened)
SIGNAL_POSITIVE_THRESHOLD=1.0

# Negative: delta <= this threshold (harmful)
SIGNAL_NEGATIVE_THRESHOLD=-1.0

# --- Reputation Adjustments (Signal-Based) ---
# Reputation change on positive signal (typically positive)
SIGNAL_REPUTATION_POSITIVE_DELTA=10

# Reputation change on negative signal (typically negative)
SIGNAL_REPUTATION_NEGATIVE_DELTA=-20

# --- Measurement Weights for Signal Delta Computation ---
# Weight of passed hypothesis count change in delta calculation
SIGNAL_WEIGHT_PASSED_HYPOTHESIS_COUNT=1.0

# Weight of mean confidence change
SIGNAL_WEIGHT_MEAN_CONFIDENCE=0.8

# Weight of graph density change
SIGNAL_WEIGHT_GRAPH_DENSITY=0.5

# Weight of filtered-to-total ratio change
SIGNAL_WEIGHT_FILTERED_RATIO=0.3

# --- Measurement Max Deltas for Normalization ---
# Expected maximum change in passed hypothesis count (for normalization)
SIGNAL_MAX_DELTA_PASSED_HYPOTHESIS_COUNT=100

# Expected maximum change in mean confidence
SIGNAL_MAX_DELTA_MEAN_CONFIDENCE=20

# Expected maximum change in graph density
SIGNAL_MAX_DELTA_GRAPH_DENSITY=0.2

# Expected maximum change in filtered-to-total ratio
SIGNAL_MAX_DELTA_FILTERED_RATIO=0.5
# System Safety Caps (New)
SYSTEM_MAX_PAPERS_PER_JOB=100
SYSTEM_MAX_FETCH_CYCLES=5
SYSTEM_MAX_GRAPH_SIZE=5000

